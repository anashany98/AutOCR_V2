# Manual de Usuario - AutoOCR Enterprise

## üìã Tabla de Contenidos
1. [Introducci√≥n](#introducci√≥n)
2. [Arquitectura del Sistema](#arquitectura-del-sistema)
3. [Componentes Principales](#componentes-principales)
4. [Gu√≠a de Uso](#gu√≠a-de-uso)
5. [Caracter√≠sticas Avanzadas](#caracter√≠sticas-avanzadas)
6. [Soluci√≥n de Problemas](#soluci√≥n-de-problemas)

---

## Introducci√≥n

**AutoOCR** es un sistema inteligente de gesti√≥n documental que combina reconocimiento √≥ptico de caracteres (OCR) de √∫ltima generaci√≥n con inteligencia artificial local para procesar, organizar y consultar documentos empresariales.

### ¬øQu√© hace AutoOCR?
- üìÑ **Digitaliza** documentos escaneados, PDFs e im√°genes
- üß† **Extrae** texto, tablas y datos estructurados autom√°ticamente
- üîç **Busca** informaci√≥n sem√°ntica en tu archivo hist√≥rico
- üí¨ **Responde** preguntas sobre tus documentos usando IA local
- üóÇÔ∏è **Organiza** con carpetas y versionado (pr√≥ximamente)

---

## Arquitectura del Sistema

```mermaid
graph TB
    subgraph "Frontend - Interfaz Web"
        UI[Navegador Web<br/>Puerto 5001]
    end
    
    subgraph "Backend - Flask App"
        FLASK[Flask Server]
        ROUTES[API Routes]
        TASKS[Huey Task Queue]
    end
    
    subgraph "Procesamiento OCR"
        PADDLE[PaddleOCR v4<br/>GPU CUDA]
        EASY[EasyOCR<br/>Backup]
        PREPROC[Pre-procesamiento<br/>OpenCV]
    end
    
    subgraph "Inteligencia Artificial"
        LLM[LM Studio<br/>Llama 3.2/Mistral]
        RAG[RAG Manager<br/>Embeddings]
        VISION[Vision Manager<br/>CLIP]
    end
    
    subgraph "Almacenamiento"
        DB[(SQLite DB<br/>Metadata)]
        FILES[Archivos<br/>data/uploads]
        INDEX[FAISS Index<br/>Vectores]
    end
    
    UI --> FLASK
    FLASK --> ROUTES
    ROUTES --> TASKS
    
    TASKS --> PREPROC
    PREPROC --> PADDLE
    PREPROC --> EASY
    
    ROUTES --> RAG
    RAG --> LLM
    ROUTES --> VISION
    
    PADDLE --> DB
    EASY --> DB
    RAG --> INDEX
    TASKS --> FILES
    
    style PADDLE fill:#4CAF50
    style LLM fill:#2196F3
    style DB fill:#FF9800
```

### Flujo de Datos

```mermaid
sequenceDiagram
    participant U as Usuario
    participant W as Web UI
    participant Q as Cola de Tareas
    participant P as Pre-procesamiento
    participant O as Motor OCR
    participant D as Base de Datos
    participant R as RAG/IA
    
    U->>W: Sube documento (PDF/imagen)
    W->>Q: Encola tarea OCR
    Q->>P: Inicia procesamiento
    P->>P: Deskew + Denoise
    P->>O: Env√≠a imagen limpia
    O->>O: PaddleOCR extrae texto
    O->>D: Guarda resultados
    D->>R: Indexa en RAG
    R-->>U: Documento disponible para consulta
```

---

## Componentes Principales

### 1. Motores OCR

**PaddleOCR v4 (Principal)**
- Motor chino de √∫ltima generaci√≥n
- Aceleraci√≥n GPU (CUDA)
- Especializado en tablas y layouts complejos
- Detecta autom√°ticamente orientaci√≥n del texto

**EasyOCR (Respaldo)**
- Respaldo si PaddleOCR falla
- Soporte multi-idioma (espa√±ol/ingl√©s)
- Modo CPU/GPU flexible

**Pre-procesamiento Inteligente** ‚≠ê *Nuevo*
- **Deskew**: Endereza documentos escaneados torcidos
- **Denoise**: Elimina ruido y manchas
- **Upscaling**: Mejora im√°genes de baja resoluci√≥n

### 2. Base de Datos

**SQLite** (Actual)
- Base de datos embebida para desarrollo
- Ubicaci√≥n: `data/digitalizerai.db`
- Almacena metadatos, texto OCR, historial de chat

**Tablas Clave**:
- `documents`: Registro de archivos procesados
- `ocr_texts`: Contenido extra√≠do
- `folders`: Organizaci√≥n jer√°rquica *(en desarrollo)*
- `document_versions`: Control de cambios *(en desarrollo)*

### 3. Sistema RAG (Retrieval-Augmented Generation)

**¬øQu√© es RAG?**
RAG combina b√∫squeda sem√°ntica con IA generativa para responder preguntas precisas basadas en tus documentos.

**C√≥mo Funciona**:
1. Cada documento se divide en "chunks" de ~300 palabras
2. Se genera un embedding (vector num√©rico) por cada chunk
3. Cuando haces una pregunta, se buscan los chunks m√°s relevantes
4. La IA responde usando **solo** ese contexto

**Citas Autom√°ticas** ‚≠ê *Nuevo*
- Ahora la IA cite sus fuentes: `[ID: 15]`
- Verificaci√≥n inmediata del origen de la informaci√≥n

### 4. Integraci√≥n con LM Studio

AutoOCR usa **LM Studio** como cerebro local:
- Sin costes de API (OpenAI, Google, etc.)
- Privacidad total (datos nunca salen de tu red)
- Modelos compatibles: Llama, Mistral, Phi, etc.

---

## Gu√≠a de Uso

### Dashboard Principal

![Dashboard Principal](dashboard.png)

El dashboard muestra:
- **Total documentos**: Archivos procesados
- **Pendientes**: Documentos sin procesar
- **Estado OCR**: Salud del sistema
- **Gr√°fica temporal**: Actividad de procesamiento

### Subir Documentos

1. Click en **"Subir Documentos"**
2. Arrastra archivos o click en **"Seleccionar"**
3. Formatos aceptados: PDF, JPG, PNG, TIFF
4. El sistema procesar√° autom√°ticamente en segundo plano

**Estado de Procesamiento**:
- üü° Pendiente
- üîµ Procesando
- üü¢ Completado
- üî¥ Error

### Gesti√≥n de Documentos

![Explorador de Documentos](documents.png)

**Acciones Disponibles**:
- **Ver**: Abre el visor con texto extra√≠do
- **Exportar**: Descarga como TXT/JSON/Excel
- **Eliminar**: Borra documento y datos asociados
- **Buscar**: Filtro por nombre o contenido

### Visor de Documentos

![Visor de Detalles](viewer.png)

**Pesta√±as**:
- **Vista Previa**: Imagen original del documento
- **Texto**: Contenido extra√≠do (editable)
- **Markdown**: Versi√≥n formateada
- **Tablas**: Datos estructurados
- **Metadatos**: Info t√©cnica (fecha, tama√±o, etc.)

### Chat Inteligente

![Interfaz de Chat](chat.png)

**Ejemplos de Preguntas**:
```
"¬øCu√°l fue el gasto total en energ√≠a este mes?"
"Busca todas las facturas de FakeCompany S.L."
"¬øQu√© documentos mencionan 'garant√≠a extendida'?"
```

**Respuesta T√≠pica**:
```
El gasto total en energ√≠a fue 1,245.50‚Ç¨ [ID: 127]
seg√∫n la factura de Iberdrola del 15/12/2023.
```

**Bot√≥n [ID: 127]**: Click para abrir ese documento espec√≠fico.

---

## Caracter√≠sticas Avanzadas

### 1. Carpetas Jer√°rquicas *(Desactivado)*

Organiza documentos en estructura de √°rbol:
```
üìÅ Facturas
  ‚îú‚îÄ‚îÄ üìÅ 2024
  ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ Enero
  ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ Febrero
  ‚îî‚îÄ‚îÄ üìÅ 2023
üìÅ Contratos
üìÅ N√≥minas
```

**Activar**: `config.yaml` ‚Üí `features.enable_folders: true`

### 2. Control de Versiones *(Desactivado)*

Guarda snapshots antes de cada edici√≥n:
- Restaura versiones antiguas
- Rastrea qui√©n cambi√≥ qu√©
- Auditor√≠a completa

**Activar**: `config.yaml` ‚Üí `features.enable_versioning: true`

### 3. Exportaci√≥n Masiva

**Formatos Disponibles**:
- **Excel**: Tablas extra√≠das en .xlsx
- **JSON**: Datos estructurados para APIs
- **TXT**: Texto plano
- **Markdown**: Formato con encabezados

**Uso**: Selecciona m√∫ltiples docs ‚Üí "Exportar Lote"

### 4. Configuraci√≥n LLM

![Configuraci√≥n del Sistema](config.png)

**Par√°metros Clave**:
- **Base URL**: `http://host.docker.internal:1234/v1`
- **Modelo**: Nombre exacto en LM Studio (ej: `llama-3.2-1b`)
- **Timeout**: 60s recomendado
- **Temperatura**: 0.7 (creatividad moderada)

---

## Soluci√≥n de Problemas

### ‚ùå "No detecta LM Studio"

**S√≠ntomas**: Chat responde "‚ö†Ô∏è No detecto LM Studio ejecut√°ndose"

**Soluci√≥n**:
1. Abre LM Studio en tu PC
2. Aseg√∫rate de que el servidor est√° en puerto 1234
3. Verifica firewall (permite conexiones en ese puerto)
4. En `config.yaml`, confirma:
   ```yaml
   base_url: http://host.docker.internal:1234/v1
   ```

### ‚ùå OCR devuelve texto vac√≠o

**Causas Comunes**:
- Imagen demasiado borrosa
- Idioma no soportado
- Documento escaneado en negativo

**Soluci√≥n**:
1. Re-escanea con mayor DPI (300+ recomendado)
2. Verifica que `lang: spa` est√© en config para espa√±ol
3. Invierte colores si el documento es negativo

### ‚ùå Documentos no aparecen

**Verificar**:
```bash
# En PowerShell (desde la carpeta del proyecto)
docker exec autoocr_gpu ls -la /app/data/uploads
```

Si est√° vac√≠o, el volumen Docker no est√° montado.

**Fix**: Reconstruye container:
```bash
docker-compose down
docker-compose up --build -d
```

### ‚ùå Error "CUDA not available"

**S√≠ntomas**: OCR muy lento, logs dicen "using CPU"

**Soluci√≥n**:
1. Instala NVIDIA Docker Runtime:
   ```bash
   nvidia-smi  # Debe mostrar tu GPU
   ```
2. Verifica `docker-compose.yml`:
   ```yaml
   deploy:
     resources:
       reservations:
         devices:
           - driver: nvidia
   ```

---

## Glosario

- **OCR**: Optical Character Recognition (Reconocimiento √ìptico de Caracteres)
- **RAG**: Retrieval-Augmented Generation (b√∫squeda + generaci√≥n de respuestas)
- **Embedding**: Representaci√≥n vectorial de texto para b√∫squeda sem√°ntica
- **Deskew**: Correcci√≥n de inclinaci√≥n en im√°genes escaneadas
- **Chunk**: Fragmento de texto (t√≠picamente 300-500 palabras)
- **LLM**: Large Language Model (Modelo de Lenguaje Grande)

---

## Soporte T√©cnico

**Documentaci√≥n T√©cnica**: Ver [walkthrough.md](file:///c:/Users/Usuario/.gemini/antigravity/brain/1ec57444-8788-42dd-88b1-b07c3ce32b4d/walkthrough.md)

**Logs del Sistema**:
```bash
docker logs autoocr_gpu --tail 100
```

**Base de Datos**:
```bash
docker exec autoocr_gpu sqlite3 /app/data/digitalizerai.db
```

---

*Versi√≥n: 2.0 Enterprise | √öltima actualizaci√≥n: Enero 2026*
